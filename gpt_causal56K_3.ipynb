{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-30T06:43:34.441072Z","iopub.status.busy":"2024-07-30T06:43:34.440646Z","iopub.status.idle":"2024-07-30T06:43:49.480607Z","shell.execute_reply":"2024-07-30T06:43:49.479552Z","shell.execute_reply.started":"2024-07-30T06:43:34.441037Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\n","Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.2\n"]}],"source":["!pip install transformers datasets evaluate"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:03.558152Z","iopub.status.busy":"2024-07-30T06:44:03.557786Z","iopub.status.idle":"2024-07-30T06:44:08.334505Z","shell.execute_reply":"2024-07-30T06:44:08.333689Z","shell.execute_reply.started":"2024-07-30T06:44:03.558121Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1470559a653a4df2927f240626e96bf9","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/485 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ac3c71f657d43c5b9866149d48e3b58","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/60.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80bc5e15a40b4bb89c530c4f1501d1fb","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/56402 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"toughdata/quora-question-answer-dataset\", split=\"train\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:08.337463Z","iopub.status.busy":"2024-07-30T06:44:08.337047Z","iopub.status.idle":"2024-07-30T06:44:08.388299Z","shell.execute_reply":"2024-07-30T06:44:08.387254Z","shell.execute_reply.started":"2024-07-30T06:44:08.337437Z"},"trusted":true},"outputs":[],"source":["ds = ds.train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:08.392233Z","iopub.status.busy":"2024-07-30T06:44:08.391612Z","iopub.status.idle":"2024-07-30T06:44:08.567608Z","shell.execute_reply":"2024-07-30T06:44:08.566349Z","shell.execute_reply.started":"2024-07-30T06:44:08.392203Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'question': \"Is there a way to permanently delete files on a computer where even the FBI can't find the info?\",\n"," 'answer': 'TL;DR: While it might be theoretically possible to multiply overwrite the bytes of individual files to prevent recovery, in practical terms it’s extremely likely you’ll miss something, so you need to wipe the entire drive. For most people it will be sufficient to just use a tool like nwipe to overwrite the entire drive with gibberish several times. If you want paranoid levels of certainty, then you need to physically destroy the storage medium inside the drive.\\n A friend recently asked me this about some drives with medical data that they needed to ensure were unrecoverable, for patient privacy reasons and legal due diligence. I gave them my advice, then double-checked it with a friend who does computer forensics, and my friend confirmed it.\\n In a nutshell, as is almost always the case in technology questions, “it depends”… on how much time, energy and technical expertise somebody wants to throw at recovering your data.\\n Cloud Backups\\n First, before we get into the drive itself, make sure that your data is not automatically backed up onto some cloud service, somewhere. This is very common for smartphones and tablets, and it’s the easiest way for The Government to get at your data. They don’t even need to come to your house, they can just send Google or Apple or whoever a subpoena.\\n To be truly safe from this attack vector, of course, you should make sure your data never leaves your device to begin with. Once a copy of your data leaves your device, it’s impossible to be certain that there’s no copy of it, anywhere.\\n Drive Hardware\\n For most people, most of the time, simply overwriting the disk several times with pseudo-random* data will make the old data unrecoverable by any reasonable forensics effort. And by “reasonable” I mean “reasonably likely to occur”. Nobody’s going to throw a year of NSA manpower at recovering your data.\\n The next level up is simply to destroy, beyond repair, the drive’s ability to function.\\n The next level up from that is to use a very thorough definition of “beyond repair”.\\n (* Computers cannot mathematically generate truly random data, but they can fake it well enough for most purposes by generating seemingly-random data; data that does have a pattern, but the pattern is so immense that for all practical purposes it might as well be random. Modern cryptography is based on this stuff, so it’s sufficient for most purposes.)\\n Overwriting The Data\\n Use nwipe or a similar open source** tool to overwrite the entire drive with pseudorandom data, multiple times.\\n Realistically, 99.99% of people just need to overwrite the entire drive a single time. But in theory, experts using very sensitive tools can read the previous magnetic charges in the drive. It’s harder to do if you overwrite the drive with pseudorandom data than just all zeroes, and it’s even harder to do if you overwrite the drive several times.\\n Also, drives and operating systems are complicated things, and even a technology-competent person might conceivably miss some area of the drive. These tools are designed by experts to make sure every single bit (literally!) of the drive gets overwritten.\\n Nwipe is the replacement for a used-to-be very popular (among geeks) open source tool for this, “dban”, aka “Darik’s Boot And Nuke”. But dban was bought by a company who then discontinued dban in favor of their commercial product, and the open source community forked the dban code and came out with nwipe.\\n (** A bedrock principle of modern cryptography, which extends to related topics like security, is that if the math and/or code is secret, it’s weak.)\\n Destroying The Drive, Easy Level\\n The easiest thing to do is to just drill a few holes through the drive. You can just get a drill and a bit that’s designed to drill through metal, and drill three to five holes straight through the case.\\n For a little extra measure, take the board (green plastic bit) off the drive and break it up and dispose of it separately from the rest of the drive.\\n Destroying the Drive, Medium Level\\n If you want to be really sure, spend a little effort taking the drive apart and make sure you’re directly damaging the storage medium — the spinning platter on an old style mechanical hard drive:\\nSource: [LINKED_TEXT: File:Inside of hard disk drive.jpg - Wikimedia Commons] [URL: https://commons.wikimedia.org/wiki/File:Inside_of_hard_disk_drive.jpg]\\n Or the memory chips in an SSD drive (the black rectangles in the photo):\\nSource: [LINKED_TEXT: File:Sf-ssd.jpg - Wikimedia Commons] [URL: https://commons.wikimedia.org/wiki/File:Sf-ssd.jpg]\\n Destroying the Drive, Hard Level\\n The next threat level up from that is quite a jump of unlikeliness — we’re talking about The Government or similar state-level actors having experts spend months or years painstakingly reconstructing the physical bits and pieces of the storage medium from the drive, then putting them under the magnetic equivalent of a microscope to find the faint traces of the original data.\\n But if you’re really, seriously worried about that, take apart the drive and heat the platter up to red hot with a blow torch or something, then let it cool and smash it into pieces. Or drop it in something corrosive enough to eat metal and plastic — a brief bath in the right strength of acid, a longer bath in salt water, etc. For SSD drives, melt the memory chips, let them cool and then smash them to itty bitty little pieces.\\n'}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["ds[\"train\"][0]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:08.569792Z","iopub.status.busy":"2024-07-30T06:44:08.568985Z","iopub.status.idle":"2024-07-30T06:44:38.023706Z","shell.execute_reply":"2024-07-30T06:44:38.022786Z","shell.execute_reply.started":"2024-07-30T06:44:08.569765Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5d03924f27a49e8844c4433eedaa37e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7279a1c26e76407593198d0ad8cc9f8c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebd339ff8c6d4becbada507a0d7ac4fc","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c00c3ffc098340a587145b0dd487faa2","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35edf90db5664959b971b52d69834d99","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7ab046fc63c40549d2185672ac6d9ba","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/45121 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"361feab2e10d4f038cee96e5bb80de90","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/11281 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","\n","# def formatting_prompts_func(example):\n","#     output_texts = {}\n","#     for i in range(len(example['question'])):\n","#         text = f\"### Question: {example['question'][i]}\\n ### Answer: {example['answer'][i]}\"\n","#         output_texts.update(text)\n","#     return output_texts\n","\n","# processed_ds = ds.map(formatting_prompts_func, batched=True)\n","\n","prefix = \"Question: \"\n","\n"," \n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"question\"]]\n","    inputs = [doc + \" Answer: \" + doc2 for doc,doc2 in zip(inputs,examples[\"answer\"])]\n","    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n","    return model_inputs\n","\n","tokenized_ds = ds.map(preprocess_function, batched=True,remove_columns=ds[\"train\"].column_names, )"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:38.025260Z","iopub.status.busy":"2024-07-30T06:44:38.024786Z","iopub.status.idle":"2024-07-30T06:44:38.032693Z","shell.execute_reply":"2024-07-30T06:44:38.031540Z","shell.execute_reply.started":"2024-07-30T06:44:38.025232Z"},"trusted":true},"outputs":[],"source":["block_size = 128\n","\n","\n","def group_texts(examples):\n","    # Concatenate all texts.\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n","    # customize this part to your needs.\n","    if total_length >= block_size:\n","        total_length = (total_length // block_size) * block_size\n","    # Split by chunks of block_size.\n","    result = {\n","        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:38.034544Z","iopub.status.busy":"2024-07-30T06:44:38.034198Z","iopub.status.idle":"2024-07-30T06:44:51.878450Z","shell.execute_reply":"2024-07-30T06:44:51.877538Z","shell.execute_reply.started":"2024-07-30T06:44:38.034512Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b593d0334c4e6cb3b8c6ed5786f04c","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/45121 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd6437bc8e8d4e9aa459b7462e04084b","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/11281 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["lm_dataset = tokenized_ds.map(group_texts, batched=True, num_proc=4)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:44:51.880149Z","iopub.status.busy":"2024-07-30T06:44:51.879825Z","iopub.status.idle":"2024-07-30T06:45:03.958554Z","shell.execute_reply":"2024-07-30T06:45:03.957662Z","shell.execute_reply.started":"2024-07-30T06:44:51.880119Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-30 06:44:54.157953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-30 06:44:54.158089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-30 06:44:54.292216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:45:03.960693Z","iopub.status.busy":"2024-07-30T06:45:03.959907Z","iopub.status.idle":"2024-07-30T06:45:19.208884Z","shell.execute_reply":"2024-07-30T06:45:19.207897Z","shell.execute_reply.started":"2024-07-30T06:45:03.960662Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3822b3ce14a64019a95fa98368e4d49c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccc4a7f97f224634b55e8c5039025814","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n","\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:45:19.210580Z","iopub.status.busy":"2024-07-30T06:45:19.210278Z","iopub.status.idle":"2024-07-30T06:45:20.327968Z","shell.execute_reply":"2024-07-30T06:45:20.327215Z","shell.execute_reply.started":"2024-07-30T06:45:19.210554Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"gpt2-qa\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    push_to_hub=True,\n","#     predict_with_generate=True,\n","    fp16=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=lm_dataset[\"train\"],\n","    eval_dataset=lm_dataset[\"test\"],\n","    data_collator=data_collator,\n","#     compute_metrics = compute_metrics\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T06:45:20.329405Z","iopub.status.busy":"2024-07-30T06:45:20.329084Z","iopub.status.idle":"2024-07-30T07:36:51.244779Z","shell.execute_reply":"2024-07-30T07:36:51.243785Z","shell.execute_reply.started":"2024-07-30T06:45:20.329369Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240730_064548-s00gcs3p</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/kkviper1-self/huggingface/runs/s00gcs3p' target=\"_blank\">gpt2-qa</a></strong> to <a href='https://wandb.ai/kkviper1-self/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/kkviper1-self/huggingface' target=\"_blank\">https://wandb.ai/kkviper1-self/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/kkviper1-self/huggingface/runs/s00gcs3p' target=\"_blank\">https://wandb.ai/kkviper1-self/huggingface/runs/s00gcs3p</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6306' max='6306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6306/6306 50:43, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.235100</td>\n","      <td>3.081926</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.068400</td>\n","      <td>2.981990</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.013300</td>\n","      <td>2.958890</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=6306, training_loss=3.1610127263624177, metrics={'train_runtime': 3089.8551, 'train_samples_per_second': 32.649, 'train_steps_per_second': 2.041, 'total_flos': 6589850370048000.0, 'train_loss': 3.1610127263624177, 'epoch': 3.0})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["\n","trainer.train()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T07:36:51.246926Z","iopub.status.busy":"2024-07-30T07:36:51.246203Z","iopub.status.idle":"2024-07-30T07:38:16.473320Z","shell.execute_reply":"2024-07-30T07:38:16.472281Z","shell.execute_reply.started":"2024-07-30T07:36:51.246878Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='523' max='523' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [523/523 01:25]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import math\n","\n","eval_results = trainer.evaluate()\n","perplexity = math.exp(eval_results['eval_loss'])\n","eval_results['perplexity'] = perplexity"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T07:38:16.476627Z","iopub.status.busy":"2024-07-30T07:38:16.476285Z","iopub.status.idle":"2024-07-30T07:38:16.482280Z","shell.execute_reply":"2024-07-30T07:38:16.481321Z","shell.execute_reply.started":"2024-07-30T07:38:16.476581Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'eval_loss': 2.9588897228240967, 'eval_runtime': 85.2137, 'eval_samples_per_second': 98.024, 'eval_steps_per_second': 6.138, 'epoch': 3.0, 'perplexity': 19.27655754797413}\n"]}],"source":["print(eval_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
